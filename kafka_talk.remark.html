<!DOCTYPE html>
<html>
  <head>
    <title>PWL CO #4 -- Kafka</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <style type="text/css">
      @import url(http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(http://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
      @import url(http://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body { font-family: 'Droid Serif'; }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: normal;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
    </style>
  </head>
  <body>
    <textarea id="source">
class: center, middle
# The Kafka paper
## LinkedIn's log aggregator and more

tim.schmelmer@gmail.com
???
- Hi everyone, I am Tim, and I work on the Consumer Shared Services team at LivingSocial
- We build a lot of services there, and we -as so many other- have been heavily abusing resque
  as a (Ruby) replacement for an inter-app messaging solution
- We have recent;y decided to clean that up and replace it with a true message bus, and Kafka had been one of the alternatives
- This triggered my interest in its design, so I read the original paper on it, and became to really like it.
---
class: middle
### LinkedIn's motivation to "roll their own"

* Traditional EMBs all suck at log processing

* Existing log aggregators weren’t a good fit either
???

- Other EMBs (ActiveMQ, IBM Websphere MQ, Oracle Enterprise Messaging Service, TIBCO) not a good match for log processing:
     - a rich set of delivery guarantees often overkill for collecting log data, increase in API and system complexity
     - many systems on’t focus on high throughput (e.g., no batch APIs)
     - weak in supporting distribution (no good way to partition and store messages on several servers)
     - assume "near immediate" consumption of messages, allowing for only small queues; not a good fit for offline consumers of messages (like Data warehouse)
- Log Aggregators (Facebook’s Scribe, Yahoo’s Data Highway, Cloudera’s Flume) aren’t a good fit because:
     - mostly built for consuming log data offline (after the fact by analyzing Hadoop / NFS shares)
     - often expose implementation details (like “minute files” for Cloudera Flume)
     - “push” model (= message broker forwards data to consumers) not useful at LinkedIn, where consumers can decide how fast they can consume the messages
---
class: middle
### Terminology
* Topic
  - stream of messages published to by producer
* Broker
  - stores published messages
* Producer
  - message publishing
* Consumer
  - subscribe to broker's topic
???


- “Topic":
     - stream of messages of a particular type
     - producer can publish messages to a topic
- “Brokers”:
     - set of servers storing published messages
- “Producer”:
     - publishes messages to a (set of) topic(s)
     - sample code:
    ````
    producer = new Producer(...);
    message = new Message(“test message str”.getBytes());
    set = new MessageSet(message);
    producer.send(“topic1”, set);
    ````
      - Note:
          — the producer can send a set of messages in a single publish request
- “Consumer”:
     - can subscribe to one or more topics from the brokers
     - sample code:
     ````
     streams[] = Consumer.createMessageStreams(“topic1”, 1);
     for (message : streams[0]) {
          bytes = message.payload();
          // do something with the bytes
     }
     ````
       - Note:
          — consumer first creates one or more message streams for the topic. The messages published to that
topic will be evenly distributed into these sub-streams
          —  message stream iterator never terminates. If there are no more messages to consume, the iterator blocks until new messages are published to the topic
          —  point-to- point delivery model: multiple consumers jointly consume a single copy of all messages in a topic,
          —  publish/subscribe model: multiple consumers each retrieve its own copy of a topic
---
class: middle, center
### Overall architecture
![kafka-arch.png 480x362 pixels](https://www.evernote.com/shard/s153/sh/2a1301a8-c374-480e-9295-24ce086e027b/a9cb8848b947e4997c6bb267537797c2/res/cd2a9fac-84ca-453d-a033-815114574371.png?resizeSmall&width=400)
???
-  Kafka cluster consists of multiple brokers
-  topic is divided into multiple partitions, each broker stores one or more of those partitions
-  multiple producers / consumers can publish / retrieve messages at the same time
---
class: middle
### Layout and efficiency of the partitioning scheme
* Partitioning
 * logical files
 * messages IDs are offsets
 * consumers can throttle

* Caching message
 * no in memory caching
 * page caching of file system + `sendfile` API

* Stateless Brokers
 * consumer holds positions in topic
 * deletion SLA time-based
???

- Efficiency on a Single Partition:
- Partitioning:
     - partition of a topic corresponds to a logical log (set of segment files of approximately the same size)
     - message is only exposed to the consumers after it is flushed to the logical log
     - messages have no unique Message ID, but are addressed by an offset in a logic log
          — avoids maintaining seek-intensive random-access index structures
          — message “IDs” (= offsets in log) are increasing but not consecutive
     - consumers issue requests to the broker, containing the message offset plus an acceptable number of bytes to fetch
          — to make transfers more efficient, each pull request from a consumer also retrieves multiple messages, even though the consumer API iterates one message at a time

- Caching message:
     - Kafka explicitly avoids caching messages in memory, instead relying on the underlying file system's page cache
          — broker restarts always with a warm cache
          — very little overhead in garbage collecting
          — exploits Linux sendfile API to directly transfer bytes from file to a socket

- Stateless Brokers:
     - information about consumer positions in topic not maintained by the broker, but by the consumers
     - deletion policy based on a time-based SLA
     - benefit: consumers can rewind back to a previous offset and re-consume data
          — nice if error in consumer application logic gets fixed, and one can replay messages from before the outage (e.g., ETL data loads into our data warehouse or Hadoop system)
          — also: if the consumer crashes, potentially unflushed data is lost. Consumer can checkpoint the smallest offset of the unflushed messages and re-consum---
---
class: middle
### Consumer / Producer / Broker interactions
* Producers
 * partition selection random, or semantic (via function)

* Consumers
 * organizable into groups
 * groups consume jointly

* Partitioning scheme
  * atom is partition in a topic
  * consumer load balancing via over-partitioning

* Zookeeper registries
  * Broker / Consumer / Ownership (ephemeral)
  * Offsets (persisted)

???
- Producers:
     - fairly uninteresting, can publish to random partition, or a partition selected semantically (via key or partition function)
- Consumers:
     - consumer group:
          — >= 1 consumer jointly consuming a (set of) topic(s), so that a message is only ever delivered to *one single consumer* in the group
 - Partitioning scheme:
     - partition in a topic is smallest unit of parallelism: all messages from one partition are consumed by a single consumer within each consumer group
          — less locking / state maintenance overhead
     - consumer load balancing: to be balanced, make many more partitions in a topic than the consumers in each group (“over- partitioning")
     - consuming processes only need co-ordinate very infrequently (= when the consumers in a group rebalance the load)
- Distribution strategies using Zookeeper (file-system like consensus service):
     - Broker registry:
          — broker’s host name and port, and the set of topics and partitions stored on it
          — ephemeral, removed when a broker fails
     - Consumer registry:
          — consumer group to which a consumer belongs and the set of topics that it subscribes to
          — ephemeral, removed when consumer fails
     - Ownership registry:
          — path for every subscribed partition, where path value is the id of the consumer currently consuming (= ‘owning’) from this partition
          — ephemeral, removes all respective entries when consumer fails
     - Offset registry:
          — for each subscribed partition, stores offset of the last consumed message in the partition
          — only persistently created Zookeeper registry
---
class: middle, center
### Consumer rebalancing
![algorithm_rebalancing.pmg 480x362 pixels](https://www.evernote.com/shard/s153/sh/2a1301a8-c374-480e-9295-24ce086e027b/a9cb8848b947e4997c6bb267537797c2/res/cdba8c94-5a46-4988-af92-fe91ab239545.png?resizeSmall&width=400)
???
* Consumer coordination strategy:
 * each consumer in a group notified of a broker or a consumer change.
 * consumer first computes the set (PT) of partitions available for each subscribed topic T and the set (CT) of consumers subscribing to T; then range-partitions PT into |CT| chunks and deterministically picks one chunk to own.
 * For each partition the consumer picks, it writes itself as the new owner of the partition in the ownership registry.
 * Finally, the consumer begins a thread to pull data from each owned partition, starting from the offset stored in the offset registry.
 * As messages get pulled from a partition, the consumer periodically updates the latest consumed offset in the offset registry.
 * Conflict resolution (when a consumer tries to take ownership of a partition still owned by another consumer):
   * first consumer releases all the partitions it currently owns, backs off and re-enters the above ‘reballancing’ process
   * theoretically infinitely stuck in this process, but in practice “rebalance process often stabilizes after only a few retries"
---
class: middle
### Delivery guarantees
* at least once

* in order

* messages uncorruption

* no broker redundance

???
- Delivery Guarantees
     - at least once:
          — in the cases where a consumer process crashes without a clean shutdown / doesn’t correctly report back the last consumed message offset, the consumer process that takes over those partitions owned by the failed consumer may get some duplicate messages.
     - in order:
          — … but only for messages in the same partition, *not* across partitions in the same topic.
     - guarding against corrupted messages:
          — Kafka stores a CRC for each message in the log
          — CRC at the message level allow for checks of I/O error on broker machine, as well as of network errors after a message is produced / consumed
     - if broker goes down:
          — any message stored on it not yet consumed becomes unavailable. If the storage system on a broker is permanently damaged, any unconsumed message is lost forever.
          — plans to add built-in replication of messages across multiple brokers to address this
---
class: middle, center
### LinkedIn's deployment
![kafka-deploy.png 452x424 pixels](https://www.evernote.com/shard/s153/sh/2a1301a8-c374-480e-9295-24ce086e027b/a9cb8848b947e4997c6bb267537797c2/res/fedf60dc-c0cc-454a-89ac-37783fc8bfec.png?resizeSmall&width=500)
???
- frontend services generate log data and publish it to brokers in batches.
     — rely on load-balancer to evenly distribute to the brokers
- online (real-time) consumers run in services within the same datacenter
- another cluster of Kafka in a separate datacenter
     — for offline analysis, located geographically close to our Hadoop cluster and other data warehouse infrastructure
     — also, for prototyping and to run scripts against the raw event streams for ad hoc querying.
- end-to-end latency: 10 seconds on average
- data processed: 100’s of gigabytes of data / ~ 1,000,000,000 messages per day
     — not all legacy systems converted to use Kafka at that point
- rebalance process: automatically redirect consumption when Ops starts / stops brokers
- auditing system:
     — messages carry the timestamp and server name when generated.
     — each producer periodically generates a monitoring event, recording # of messages published for each topic within a fixed time window, and publishes monitoring events to a separate topic
     — consumers count # of messages they have received from a given topic and validate those counts with the monitoring events
- sucking data into Hadoop / Data Warehouse:
     — MapReduce jobs load the raw data & regroups and compresses it for efficient further processing
     — stateless broker / client-side storage of offsets allow MapReduce tasks (which can fail and be restarted) to be managed to handle data load without duplicating / losing messages
- serialization protocol: Apache Avro
     — because message schemas can evolve
     — Messages store the ID of the Avro schema along with the message (= raw bytes)
     — allows for enforcing a contract between data producers and consumers, to ensure compatibility
          —> they use a schema registry to retrieve the schema
---
class: middle, center
### Performance results
![kafka-producer-perf.png 452x424 pixels](https://www.evernote.com/shard/s153/sh/2a1301a8-c374-480e-9295-24ce086e027b/a9cb8848b947e4997c6bb267537797c2/res/48b66dce-42d2-494f-8d6e-313f1d54b51d.png?resizeSmall&width=225)
![kafka-consumer-perf.png 452x424 pixels](https://www.evernote.com/shard/s153/sh/2a1301a8-c374-480e-9295-24ce086e027b/a9cb8848b947e4997c6bb267537797c2/res/ba13ef69-d4c2-4c2d-bf28-14fba34e603b.png?resizeSmall&width=225)
???
- comparisons to ActiveMQ v5.4/ JMS, and RabbitMQ v2.4
- test set-up:
     — 2 Linux machines(8 2GHz cores, 16GB mem, 6 disks RAID 10), connected via 1Gb network link.
     — 1 machine broker, 1 producer or consumer.
- Producer tests:
     — one producer to publish 10 million messages with 200 bytes
     — batch sizes 1 vs 50. (ActiveMQ and RabbitMQ can’t easily batch messages)
     — Kafka better because:
          — if doesn’t wait for ACK from broker
          — overhead of 9 bytes per msg in Kafka vs144 bytes in ActiveMQ. => ActiveMQ was using 70% more space than Kafka to store the same set of 10 million messages.
- Consumer test:
     — one consumer to retrieve10 millions messages
     — each pull request fetched ~ 1000 messages / ~ 200KB
     — ActiveMQ and RabbitMQ set to acknowledge automatically
     — messages fit in memory, all systems were serving data from the page cache of the underlying file system or some in-memory buffers
     — Kafka better because:
          — Kafka has more efficient storage format, fewer bytes to transferred to consumer
          — broker in ActiveMQ and RabbitMQ has to maintain delivery state of every message
          — in using the sendfile API, Kafka reduces transmission overhead
---
class: middle
### Future work / Conclusion
* Durability and availability
  * broker replication

* Stream processing
  * library support for joins and windowing

???

- Durability and data availability guarantees:
      — add built-in replication of messages across multiple brokers to address unrecoverable broker failures

- Stream processing capabilities
     — plans for a library of helpful stream utilities, (windowing functions, join techniques, etc.)
          — window-based counting and joining each message with records in a secondary store or with messages in another stream
---
class: middle
### My personal take-aways
* designed log data only
  * first and foremost use case now is [messaging](http://kafka.apache.org/documentation.html#uses)

* build specialized systems with less feature bloat

???
- Very much focussed on log data only, while now more used as a general Enterprise Messaging Bus
  - Interesting to see it was developed with log data as its main intent, given the first use case cited

- The papaer says that its main take-away is "to illustrate the potential performance gain that can be achieved by a specialized system"
  - while the intent was to avoid feature bloat, the documentation makes it sound like it is *also* a silver bullet for
    - Messaging, Website Activity Tracking, Metrics, Stream Processing, Event Sourcing, Commit Logs, ...

---
class: middle
### References
* [Kafka: a Distributed Messaging System for Log Processing](http://research.microsoft.com/en-us/um/people/srikanth/netdb11/netdb11papers/netdb11-final12.pdf)

* This presentation at: [http://timbogit.github.io/kafka_talk.remark.html](http://timbogit.github.io/kafka_talk.remark.html)
???
- This pretty much all I wanted to mention for today
- There are some great references out there on the web for this topic
  - the first one is a good overview of this topic, more in-depth around the actual protocol behind this
  - Wikipedia's entry about ETags is a very useful read, as well
  - albeit a little dated, the "Advanced Caching in Rails" guide is very in-depth and offers lots of practical
    advice
  - and lastly, the bit.ly URL points you to my drop-box share which holds this HTML/MarkDown presentation
    </textarea>
    <script src="http://gnab.github.io/remark/downloads/remark-latest.min.js" type="text/javascript">
    </script>
    <script type="text/javascript">
      var slideshow = remark.create();
    </script>
  </body>
</html>
